{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAPReHPnQXD6"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics supervision\n",
        "!pip install git+https://github.com/NVlabs/describe-anything\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yj017o6CQf6y"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade numpy\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaNRX_PtBVcN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLg0IaPbB5H7"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import psutil\n",
        "from IPython.display import display, Javascript\n",
        "\n",
        "# Initialize tracking variables\n",
        "if 'start_time' not in globals():\n",
        "    start_time = time.time()\n",
        "    initial_ram = psutil.virtual_memory().used / (1024 ** 3)  # GB\n",
        "    print(\"Tracking started for all cells...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hi9ZEM0URODD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from ultralytics import SAM, YOLO\n",
        "from dam.describe_anything_model import DescribeAnythingModel\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXzSwPLQUl5b"
      },
      "outputs": [],
      "source": [
        "sam = SAM(\"sam2_b.pt\").to(DEVICE)\n",
        "print(\"SAM 2 model loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkAcedj0Uy73"
      },
      "outputs": [],
      "source": [
        "dam = DescribeAnythingModel(\n",
        "    model_path=\"nvidia/DAM-3B\",\n",
        "    conv_mode=\"v1\",\n",
        "    prompt_mode=\"full+crop\",\n",
        ")\n",
        "print(\"DAM model loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpXGGV-tUnJ4"
      },
      "outputs": [],
      "source": [
        "image_path = \"/content/1_v0Bm-HQxWtpbQ0Yq463uqw.jpg\"  # Replace with your image path\n",
        "image_bgr = cv2.imread(image_path)\n",
        "if image_bgr is None:\n",
        "    raise FileNotFoundError(f\"Image not found at {image_path}\")\n",
        "image = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.title(\"Original Image\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srg3nPvTUr8G"
      },
      "outputs": [],
      "source": [
        "results = sam(image)\n",
        "result = results[0]\n",
        "\n",
        "masks_tensor = result.masks.data  # (num_masks, H, W)\n",
        "masks = masks_tensor.cpu().numpy().astype(bool)\n",
        "\n",
        "print(f\"Generated {len(masks)} masks\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B23q4TFUXHRZ"
      },
      "outputs": [],
      "source": [
        "def overlay_mask(image, mask, color=(0, 255, 0), alpha=0.5):\n",
        "    overlay = image.copy()\n",
        "    mask_bool = mask.astype(bool)\n",
        "    overlay[mask_bool] = (overlay[mask_bool] * (1 - alpha) + np.array(color) * alpha).astype(np.uint8)\n",
        "    return overlay\n",
        "\n",
        "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]\n",
        "image_vis = image.copy()\n",
        "\n",
        "for i, mask in enumerate(masks):\n",
        "    color = colors[i % len(colors)]\n",
        "    image_vis = overlay_mask(image_vis, mask, color=color, alpha=0.4)\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(image_vis)\n",
        "plt.axis('off')\n",
        "plt.title(\"Image with SAM Masks Overlayed\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfYThmPRU3-e"
      },
      "outputs": [],
      "source": [
        "def numpy_to_pil(img_np):\n",
        "    return Image.fromarray(img_np)\n",
        "\n",
        "descriptions = []\n",
        "\n",
        "for i, mask in enumerate(masks):\n",
        "    # Convert mask to uint8 for contour detection\n",
        "    mask_uint8 = mask.astype(np.uint8) * 255\n",
        "\n",
        "    # Find bounding box of mask\n",
        "    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours:\n",
        "        continue\n",
        "    x, y, w, h = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop image and mask\n",
        "    cropped_img = image[y:y+h, x:x+w]\n",
        "    cropped_mask = mask_uint8[y:y+h, x:x+w]\n",
        "\n",
        "    # Apply mask to crop\n",
        "    masked_crop = cv2.bitwise_and(cropped_img, cropped_img, mask=cropped_mask)\n",
        "\n",
        "    # Display cropped masked object\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.title(f\"Object {i+1}\")\n",
        "    plt.imshow(masked_crop)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Convert to PIL Image for DAM\n",
        "    cropped_pil = numpy_to_pil(masked_crop)\n",
        "\n",
        "    # Generate description using correct DAM API\n",
        "    description = dam.get_description(\n",
        "        image_pil=cropped_pil,  # Pass cropped region\n",
        "        mask_pil=Image.fromarray(cropped_mask),  # Mask for the cropped area\n",
        "        query=\"<image> Describe this object in detail.\",\n",
        "        temperature=0.2,\n",
        "        top_p=0.9,\n",
        "        num_beams=1,\n",
        "        max_new_tokens=512\n",
        "    )\n",
        "\n",
        "    print(f\"Description for Object {i+1}:\\n{description}\\n\")\n",
        "    descriptions.append(description)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhxJ4OijU5SX"
      },
      "outputs": [],
      "source": [
        "import nbformat\n",
        "\n",
        "def clean_notebook(input_path, output_path=None):\n",
        "    if output_path is None:\n",
        "        output_path = input_path\n",
        "    nb = nbformat.read(input_path, as_version=4)\n",
        "    if 'widgets' in nb.get('metadata', {}):\n",
        "        del nb['metadata']['widgets']\n",
        "    nbformat.write(nb, output_path)\n",
        "\n",
        "clean_notebook(\"SAM2_WO_YOLO.ipynb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDbZc4JRDB4j"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}