{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAPReHPnQXD6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yj017o6CQf6y"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaNRX_PtBVcN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLg0IaPbB5H7"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import psutil\n",
        "from IPython.display import display, Javascript\n",
        "\n",
        "# Initialize tracking variables\n",
        "if 'start_time' not in globals():\n",
        "    start_time = time.time()\n",
        "    initial_ram = psutil.virtual_memory().used / (1024 ** 3)  # GB\n",
        "    print(\"Tracking started for all cells...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hi9ZEM0URODD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "from ultralytics import SAM\n",
        "sam = SAM(\"sam2.1_b.pt\").to(DEVICE)\n",
        "print(\"SAM 2.1 model loaded on\", DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy3TucRGTa1i"
      },
      "outputs": [],
      "source": [
        "#Helper\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0) #alpha=0.6 makes the mask semi-transparent.\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "\n",
        "def show_points(coords, labels, ax, marker_size=375):\n",
        "    pos_points = coords[labels==1]\n",
        "    neg_points = coords[labels==0]\n",
        "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "\n",
        "def show_anns(anns):\n",
        "    if len(anns) == 0:\n",
        "        return\n",
        "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
        "    ax = plt.gca()\n",
        "    ax.set_autoscale_on(False)\n",
        "\n",
        "    for ann in sorted_anns:\n",
        "        m = ann['segmentation']\n",
        "        img = np.ones((m.shape[0], m.shape[1], 3))\n",
        "        color_mask = np.random.random((1, 3)).tolist()[0]\n",
        "        for i in range(3):\n",
        "            img[:,:,i] = color_mask[i]\n",
        "        ax.imshow(np.dstack((img, m*0.35)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JNhH9B5V_jr"
      },
      "outputs": [],
      "source": [
        "print(\"SAM 2.1 model loaded on\", DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9CiOjZRWKho"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Load your image\n",
        "import cv2\n",
        "image_path = \"/content/1_v0Bm-HQxWtpbQ0Yq463uqw.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.title(\"Original Image\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UotZCYOZWor8"
      },
      "outputs": [],
      "source": [
        "# SAM 2.1: Direct mask generation with correct output handling\n",
        "results = sam(image)  # image is an RGB numpy array\n",
        "result = results[0]   # get first result (single image)\n",
        "\n",
        "masks_tensor = result.masks.data  # torch tensor (num_masks, H, W)\n",
        "masks = masks_tensor.cpu().numpy().astype(bool)  # convert to numpy boolean masks\n",
        "\n",
        "filtered_masks = [m for m in masks]  # Add filtering if needed\n",
        "\n",
        "print(f\"Total masks generated: {len(masks)}\")\n",
        "print(f\"Number of high-confidence masks: {len(filtered_masks)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noo-USqXCfV6"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "yolo = YOLO('yolov8m-world.pt').to(DEVICE)\n",
        "# Set your desired zero-shot detection classes\n",
        "yolo.set_classes(['person', 'car', 'bicycle', 'dog', 'cat', 'bus', 'truck',\"objects\"])\n",
        "print(\"YOLO-World model loaded with custom zero-shot classes.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciPHfg3VCkpq"
      },
      "outputs": [],
      "source": [
        "# Object detection function (using YOLO-World zero-shot classes)\n",
        "def detect_objects(image, score_threshold=0.1):\n",
        "    results = yolo.predict(image, conf=score_threshold, verbose=False)\n",
        "\n",
        "    detections = []\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            xyxy = box.xyxy.cpu().numpy()[0].tolist()\n",
        "            conf = box.conf.cpu().numpy()[0]\n",
        "            cls_id = int(box.cls.cpu().numpy()[0])\n",
        "            # YOLO-World: class names are set via set_classes()\n",
        "            label = yolo.model.names[cls_id] if hasattr(yolo.model, 'names') else str(cls_id)\n",
        "\n",
        "            detections.append({\n",
        "                'bbox': [int(coord) for coord in xyxy],  # [x1,y1,x2,y2]\n",
        "                'label': label,\n",
        "                'score': float(conf)\n",
        "            })\n",
        "\n",
        "    return sorted(detections, key=lambda x: x['score'], reverse=True)  # Highest score first\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AZdRYbCClh2"
      },
      "outputs": [],
      "source": [
        "# Cell 13: Load and display input image\n",
        "image_path = \"/content/1_v0Bm-HQxWtpbQ0Yq463uqw.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.title(\"Input Image\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNOY6iPNCzkU"
      },
      "outputs": [],
      "source": [
        "detections = detect_objects(image, score_threshold=0.15)\n",
        "\n",
        "print(f\"Detected {len(detections)} objects:\")\n",
        "for det in detections:\n",
        "    print(f\"- {det['label']} (confidence: {det['score']:.2f}): {det['bbox']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHkn7_1cC3oj"
      },
      "outputs": [],
      "source": [
        "vis_image = image.copy()\n",
        "\n",
        "for det in detections:\n",
        "    x1, y1, x2, y2 = det['bbox']\n",
        "    cv2.rectangle(vis_image, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
        "    label = f\"{det['label']} ({det['score']:.2f})\"\n",
        "    cv2.putText(vis_image, label, (x1, y1-10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(vis_image)\n",
        "plt.axis('off')\n",
        "plt.title(\"Detected Objects with YOLO-World\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6k9duo0C6bd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import cv2\n",
        "\n",
        "with open(\"detections.json\", \"w\") as f:\n",
        "    json.dump(detections, f, indent=2)\n",
        "\n",
        "cv2.imwrite(\"detected_objects.jpg\", cv2.cvtColor(vis_image, cv2.COLOR_RGB2BGR))\n",
        "print(\"Results saved to detections.json and detected_objects.jpg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUPDgUD9C9KH"
      },
      "outputs": [],
      "source": [
        "def calculate_iou(mask, bbox):\n",
        "    \"\"\"Compute Intersection-over-Union between mask and bbox\"\"\"\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    bbox_mask = np.zeros(mask.shape[:2], dtype=np.uint8)\n",
        "    cv2.rectangle(bbox_mask, (x1, y1), (x2, y2), 255, -1)\n",
        "    mask_bool = mask > 0\n",
        "    bbox_bool = bbox_mask > 0\n",
        "    intersection = np.logical_and(mask_bool, bbox_bool).sum()\n",
        "    union = np.logical_or(mask_bool, bbox_bool).sum()\n",
        "    return intersection / max(union, 1e-6)\n",
        "\n",
        "# For SAM 2.1, masks are already binary numpy arrays\n",
        "binary_masks = [m.astype(np.uint8) for m in filtered_masks]\n",
        "\n",
        "object_groups = []\n",
        "for det in detections:\n",
        "    group = {\n",
        "        'label': det['label'],\n",
        "        'bbox': [int(x) for x in det['bbox']],\n",
        "        'masks': []\n",
        "    }\n",
        "    for mask in binary_masks:\n",
        "        iou = calculate_iou(mask, group['bbox'])\n",
        "        if iou > 0.5:\n",
        "            group['masks'].append(mask)\n",
        "    object_groups.append(group)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hK7rXqVoDC9W"
      },
      "outputs": [],
      "source": [
        "def mask_to_bbox(mask):\n",
        "    \"\"\"Convert binary mask to bounding box coordinates [x1,y1,x2,y2]\"\"\"\n",
        "    contours, _ = cv2.findContours(mask.astype(np.uint8),\n",
        "                 cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours:\n",
        "        return None\n",
        "    x, y, w, h = cv2.boundingRect(contours[0])\n",
        "    return [x, y, x+w, y+h]\n",
        "\n",
        "final_objects = []\n",
        "\n",
        "for group in object_groups:\n",
        "    if not group['masks']:\n",
        "        continue\n",
        "\n",
        "    merged = np.zeros_like(binary_masks[0], dtype=np.uint8)\n",
        "    for mask in group['masks']:\n",
        "        merged = cv2.bitwise_or(merged, mask.astype(np.uint8))\n",
        "    bbox_coords = mask_to_bbox(merged > 0)\n",
        "    if bbox_coords is None:\n",
        "        continue\n",
        "\n",
        "    x1, y1, x2, y2 = bbox_coords\n",
        "    h, w = image.shape[:2]\n",
        "    x1, y1 = max(0, x1), max(0, y1)\n",
        "    x2, y2 = min(w, x2), min(h, y2)\n",
        "\n",
        "    if x2 <= x1 or y2 <= y1:\n",
        "        continue\n",
        "\n",
        "    cropped = image[y1:y2, x1:x2]\n",
        "    masked_crop = cv2.bitwise_and(cropped, cropped, mask=merged[y1:y2, x1:x2])\n",
        "\n",
        "    final_objects.append({\n",
        "        'label': group['label'],\n",
        "        'bbox': [x1, y1, x2, y2],\n",
        "        'merged_mask': merged[y1:y2, x1:x2],\n",
        "        'cropped_image': masked_crop\n",
        "    })\n",
        "\n",
        "print(f\"Successfully processed {len(final_objects)} objects\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6qc0XnyDHGg"
      },
      "outputs": [],
      "source": [
        "for i, obj in enumerate(final_objects):\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.title(f\"{obj['label']} - Object {i+1}\")\n",
        "    plt.imshow(obj['cropped_image'])\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnTaOfy8DLLD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "save_dir = \"cropped_objects\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "for i, obj in enumerate(final_objects):\n",
        "    cropped_img = obj['cropped_image']\n",
        "    cropped_img_rgb = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB)\n",
        "    filename = f\"{obj['label']}_object_{i+1}.png\"\n",
        "    filepath = os.path.join(save_dir, filename)\n",
        "    cv2.imwrite(filepath, cropped_img)\n",
        "    print(f\"Saved {filepath}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gu1f2ZfmDN-q"
      },
      "outputs": [],
      "source": [
        "from dam.describe_anything_model import DescribeAnythingModel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FINXhAAQDSTc"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "model = DescribeAnythingModel(\n",
        "    model_path=\"nvidia/DAM-3B\",\n",
        "    conv_mode=\"v1\",\n",
        "    prompt_mode=\"full+crop\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-YmgQQ8DTNR"
      },
      "outputs": [],
      "source": [
        "image = Image.open(\"/content/1_v0Bm-HQxWtpbQ0Yq463uqw.jpg\").convert(\"RGB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQZicC9RDWQ3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "def numpy_to_pil_mask(np_img):\n",
        "    if len(np_img.shape) == 3 and np_img.shape[2] == 3:\n",
        "        np_img = cv2.cvtColor(np_img, cv2.COLOR_BGR2RGB)\n",
        "        pil_img = Image.fromarray(np_img).convert(\"L\")\n",
        "    else:\n",
        "        pil_img = Image.fromarray(np_img).convert(\"L\")\n",
        "    return pil_img\n",
        "\n",
        "def embed_mask_in_full_image(mask_crop, bbox, full_shape):\n",
        "    full_mask = np.zeros(full_shape, dtype=np.uint8)\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    resized_mask = cv2.resize(mask_crop, (x2 - x1, y2 - y1), interpolation=cv2.INTER_NEAREST)\n",
        "    full_mask[y1:y2, x1:x2] = resized_mask\n",
        "    return full_mask\n",
        "\n",
        "descriptions = []\n",
        "\n",
        "if isinstance(image, Image.Image):\n",
        "    image_np = np.array(image)  # RGB\n",
        "    image = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "image_height, image_width = image.shape[:2]\n",
        "\n",
        "for i, obj in enumerate(final_objects):\n",
        "    bbox = obj['bbox']\n",
        "    mask_crop = obj['merged_mask']  # smaller mask cropped to bbox size or close\n",
        "    full_mask = embed_mask_in_full_image(mask_crop, bbox, (image_height, image_width))\n",
        "    image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    mask_pil = numpy_to_pil_mask(full_mask)\n",
        "\n",
        "    query = \"<image> Describe the object in the highlighted region in detail.\"\n",
        "\n",
        "    description = model.get_description(\n",
        "        image_pil=image_pil,\n",
        "        mask_pil=mask_pil,\n",
        "        query=query,\n",
        "        temperature=0.2,\n",
        "        top_p=0.9,\n",
        "        num_beams=1,\n",
        "        max_new_tokens=512,\n",
        "    )\n",
        "\n",
        "    print(f\"Description for object {i+1} ({obj['label']}):\\n{description}\\n\")\n",
        "    descriptions.append(description)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l1hERSbDYx7"
      },
      "outputs": [],
      "source": [
        "# Calculate total metrics\n",
        "total_time = time.time() - start_time\n",
        "final_ram = psutil.virtual_memory().used / (1024 ** 3)\n",
        "ram_used = final_ram - initial_ram\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"TOTAL PROCESSING TIME FOR ALL CELLS: {total_time:.2f} seconds\")\n",
        "print(f\"TOTAL RAM CONSUMPTION: {ram_used:.2f} GB\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Show GPU summary\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDbZc4JRDB4j"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m_a9zvedu6T"
      },
      "outputs": [],
      "source": [
        "\n",
        "import nbformat\n",
        "def clean_notebook(input_path, output_path=None):\n",
        "    if output_path is None:\n",
        "        output_path = input_path\n",
        "    nb = nbformat.read(input_path, as_version=4)\n",
        "    if 'widgets' in nb.get('metadata', {}):\n",
        "        del nb['metadata']['widgets']\n",
        "    nbformat.write(nb, output_path)\n",
        "\n",
        "clean_notebook(\"SAM2.1.ipynb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u74EGVhwdu6U"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}